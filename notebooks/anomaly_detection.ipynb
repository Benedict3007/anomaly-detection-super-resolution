{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d05935-e347-40de-91e3-7969195ab8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import imageio.v2 as imageio\n",
    "import logging\n",
    "import re\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "from skimage import exposure\n",
    "\n",
    "from checkpoint import Checkpoint\n",
    "from model import Model\n",
    "from data import Data\n",
    "from loss import Loss\n",
    "from trainer import Trainer\n",
    "from helpers import prepare, quantize, setup_opt_drn, setup_opt_drct, setup_logger, calculate_ssim, calculate_mse, calculate_psnr, min_max_scaling, histogram_equalization, analyze_window_sizes, analyze_window_sizes_gkd, process_images, process_gkd_images, plot_roc_curve, find_optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c755f452-ee7e-4ab6-bbed-171b97944073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: gkd\n",
      "mvtec_class: None\n",
      "gkd_class: DC2\n",
      "resolution: 128\n",
      "scaling: 8\n"
     ]
    }
   ],
   "source": [
    "model_type = 'drct'\n",
    "model_name = 'gkd_DC2_128_X813:59:20'\n",
    "\n",
    "cascading = False\n",
    "pre_model_name = 'gkd_DC2_128_X220:23:16'\n",
    "cas_model_name = 'gkd_DC2_512_X4_128_X2_64_cascading'\n",
    "\n",
    "# Extract dataset\n",
    "dataset = model_name.split('_')[0]\n",
    "\n",
    "# Extract class and resolution\n",
    "if dataset == 'mvtec':\n",
    "    mvtec_class = model_name.split('_')[1]\n",
    "    gkd_class = None\n",
    "elif dataset == 'gkd':\n",
    "    mvtec_class = None\n",
    "    gkd_class = model_name.split('_')[1]\n",
    "else:\n",
    "    mvtec_class = None\n",
    "    gkd_class = None\n",
    "\n",
    "resolution = int(re.search(r'_(\\d{2,3})_', model_name).group(1))\n",
    "\n",
    "scaling = int(re.search(r'X(\\d)', model_name).group(1))\n",
    "\n",
    "# Print results\n",
    "print(f\"dataset: {dataset}\")\n",
    "print(f\"mvtec_class: {mvtec_class}\")\n",
    "print(f\"gkd_class: {gkd_class}\")\n",
    "print(f\"resolution: {resolution}\")\n",
    "print(f\"scaling: {scaling}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d51c4a9-fd08-4e81-8e26-c8a5a1bf62b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DRN:\n",
    "    model_name: str='drn-l'\n",
    "    n_threads: int=-2 # number of threads for data loading\n",
    "    cpu: bool=False # use cpu only\n",
    "    n_GPUs: int=1 # number of GPUs\n",
    "    seed: int=1 # random seed\n",
    "    data_dir: str='./workspace/gkd/DC2/unlabeled/HR_512_grayscale/' # dataset directory\n",
    "    data_train: str='' # train dataset name\n",
    "    data_test: str='' # test dataset name\n",
    "    data_range: str='1-224/225-280' # train test data range\n",
    "    scale: int=4 # super resolution scale\n",
    "    patch_size: int=512 # output patch size\n",
    "    rgb_range: int=255 # maximum value of RGB\n",
    "    n_colors: int=1 # number of color channels to use\n",
    "    no_augment: bool=True # do not use data augmentation\n",
    "    pre_train: str='.' # pre-trained model directory\n",
    "    pre_train_dual: str='.' # pre-trained dual model directory\n",
    "    n_blocks: int=40 # number of residual blocks, 16|30|40|80\n",
    "    n_feats: int=20 # number of feature maps \n",
    "    negval: float=0.2 # Negative value parameter for Leaky ReLU\n",
    "    test_every: int=10 # do test per every N batches\n",
    "    epochs: int=10 # number of epochs to train\n",
    "    batch_size: int=4 # input batch_size for training\n",
    "    self_ensemble: bool=False # use self-ensemble method for test\n",
    "    test_only: bool=True # set this option to test the model\n",
    "    lr: float=1e-4 # learning rate\n",
    "    eta_min: float=1e-7 # eta_min learning rate\n",
    "    beta1: float=0.9 # ADAM beta1\n",
    "    beta2: float=0.999 # ADAM beta2\n",
    "    epsilon: float=1e-8 # ADAM epsilon for numerical stability\n",
    "    weight_decay: float=1e-8 # weight decay\n",
    "    loss: str='1*L1' # loss function configuration, L1/MSE\n",
    "    skip_threshold: float=1e6 # skipping batch that has large error\n",
    "    dual_weight: float=0.1 # the weight of dual loss\n",
    "    save: str='./workspace/experiment/drn-l/gkd_dc2_unlabeld_X4_10_grayscale/' # file name to save\n",
    "    print_every: int=10 # how many batches to wait before logging training status\n",
    "    save_results: bool=False # save output results\n",
    "    dual: bool=True\n",
    "    patience: int=10\n",
    "\n",
    "@dataclass\n",
    "class DRCT:\n",
    "    model_name: str='drct'\n",
    "    n_threads: int=2 # number of threads for data loading\n",
    "    cpu: bool=False # use cpu only\n",
    "    n_GPUs: int=1 # number of GPUs\n",
    "    seed: int=1 # random seed\n",
    "    data_dir: str='./workspace/gkd/DC2/unlabeled/HR_512_grayscale/' # dataset directory\n",
    "    data_train: str='' # train dataset name\n",
    "    data_test: str='' # test dataset name\n",
    "    data_range: str='1-260/261-299' # train test data range\n",
    "    scale: int=4 # super resolution scale\n",
    "    patch_size: int=512 # output patch size\n",
    "    rgb_range: int=255 # maximum value of RGB\n",
    "    n_colors: int=1 # number of color channels to use\n",
    "    no_augment: bool=True # do not use data augmentation\n",
    "    pre_train: str='.' # pre-trained model directory\n",
    "    pre_train_dual: str='.' # pre-trained dual model directory\n",
    "    negval: float=0.2 # Negative value parameter for Leaky ReLU\n",
    "    test_every: int=30 # do test per every N batches\n",
    "    epochs: int=10 # number of epochs to train\n",
    "    batch_size: int=2 # input batch_size for training\n",
    "    self_ensemble: bool=False # use self-ensemble method for test\n",
    "    test_only: bool=True # set this option to test the model\n",
    "    lr: float=1e-4 # learning rate\n",
    "    eta_min: float=1e-7 # eta_min learning rate\n",
    "    beta1: float=0.9 # ADAM beta1\n",
    "    beta2: float=0.999 # ADAM beta2\n",
    "    epsilon: float=1e-8 # ADAM epsilon for numerical stability\n",
    "    loss: str='1*L1' # loss function configuration, L1/MSE\n",
    "    skip_threshold: float=1e6 # skipping batch that has large error\n",
    "    dual_weight: float=0.1 # the weight of dual loss\n",
    "    save: str='./workspace/experiment/drct/gkd_dc2_unlabeled_X4_10_test_grayscale/' # file name to save\n",
    "    print_every: int=10 # how many batches to wait before logging training status\n",
    "    save_results: bool=False # save output results\n",
    "    dual: bool=True\n",
    "    upscale: int=4\n",
    "    img_size: int=128\n",
    "    window_size: int=16\n",
    "    compress_ratio: int=3\n",
    "    squeeze_factor: int=30\n",
    "    conv_scale: float=0.01\n",
    "    overlap_ratio: float=0.5\n",
    "    img_range: float=1.0\n",
    "    depths: list=(6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6)\n",
    "    embed_dim: int=180\n",
    "    num_heads: list=(6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6)\n",
    "    mlp_ratio: int=2\n",
    "    upsampler: str='pixelshuffle'\n",
    "    resi_connection: str='1conv'\n",
    "    ema_decay: float=0.999\n",
    "    lr: float=2e-4\n",
    "    weight_decay: float=0.0\n",
    "    betas: list=(0.9, 0.99)\n",
    "    patience: int=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef4391d-c771-4d60-9ff7-bbb0c625e61e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bd6102s/miniconda/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789563135/work/aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./workspace/experiment/drct/gkd_DC2_128_X813:59:20/model/model_best.pt\n",
      "The number of parameters is 27.48M\n"
     ]
    }
   ],
   "source": [
    "# Parameter\n",
    "scale = scaling\n",
    "no_augment = False\n",
    "epochs = 1000\n",
    "batch_size = 1 \n",
    "patch_size = resolution\n",
    "img_size = resolution // scale\n",
    "\n",
    "if dataset == 'mvtec' and mvtec_class == 'carpet':\n",
    "    n_colors = 3\n",
    "else:\n",
    "    n_colors = 1\n",
    "# n_colors = 3\n",
    "\n",
    "if dataset == 'mvtec':\n",
    "    if cascading:\n",
    "        data_dir_good = f'./workspace/images/{model_type}/{pre_model_name}/predicted_images/good'\n",
    "        data_dir_bad = f'./workspace/images/{model_type}/{pre_model_name}/predicted_images/bad'\n",
    "    else:\n",
    "        data_dir_good = f'./workspace/mvtec_anomaly_detection_modified/{mvtec_class}/test/HR_{resolution}/good'\n",
    "        data_dir_bad = f'./workspace/mvtec_anomaly_detection_modified/{mvtec_class}/test/HR_{resolution}/bad'\n",
    "    dataset_length = 256\n",
    "elif dataset == 'gkd':\n",
    "    if cascading:\n",
    "        data_dir_good = f'./workspace/images/{model_type}/{pre_model_name}/predicted_images/good'\n",
    "        data_dir_bad = f'./workspace/images/{model_type}/{pre_model_name}/predicted_images/bad'\n",
    "    else:\n",
    "        data_dir_good = f'./workspace/gkd/{gkd_class}/test/HR_{resolution}/good'\n",
    "        data_dir_bad = f'./workspace/gkd/{gkd_class}/test/HR_{resolution}/bad'\n",
    "    dataset_length = 2048\n",
    "else:\n",
    "    print(\"Not the right dataset!\")\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# data_range: str='1-800/801-1000'\n",
    "# MVTec Carpet Datarange\n",
    "data_range: str='' # train test data range\n",
    "test_every = dataset_length // batch_size\n",
    "print_every = test_every\n",
    "patience = 1000\n",
    "n_threads = 4\n",
    "\n",
    "if model_type == 'drn-l':\n",
    "    if cascading:\n",
    "        save = f'./workspace/images/drn-l/{cas_model_name}/'\n",
    "    else:\n",
    "        save = f'./workspace/images/drn-l/{model_name}/'\n",
    "    opt_drn = DRN()\n",
    "    opt_good = copy.deepcopy(opt_drn)\n",
    "    opt_bad = copy.deepcopy(opt_drn)\n",
    "    opt_good = setup_opt_drn(opt_good, scale, no_augment, n_colors, epochs, batch_size, patch_size, data_dir_good, save, data_range, test_every, print_every, patience, n_threads, model_name)\n",
    "    opt_bad = setup_opt_drn(opt_bad, scale, no_augment, n_colors, epochs, batch_size, patch_size, data_dir_bad, save, data_range, test_every, print_every, patience, n_threads, model_name)\n",
    "elif model_type == 'drct':\n",
    "    if cascading:\n",
    "        save = f'./workspace/images/drct/{cas_model_name}/'\n",
    "    else:\n",
    "        save = f'./workspace/images/drct/{model_name}/'\n",
    "    opt_drct = DRCT()\n",
    "    opt_good = copy.deepcopy(opt_drct)\n",
    "    opt_bad = copy.deepcopy(opt_drct)\n",
    "    opt_good = setup_opt_drct(opt_good, scale, no_augment, n_colors, epochs, batch_size, patch_size, img_size, data_dir_good, save, data_range, test_every, print_every, patience, n_threads, model_name)\n",
    "    opt_bad = setup_opt_drct(opt_bad, scale, no_augment, n_colors, epochs, batch_size, patch_size, img_size, data_dir_bad, save, data_range, test_every, print_every, patience, n_threads, model_name)\n",
    "else:\n",
    "    print(\"Model_Type unknown!\")\n",
    "    \n",
    "if model_type == 'drn-l':\n",
    "    checkpoint = Checkpoint(opt_good)\n",
    "    model = Model(opt_good, checkpoint, dual_model=True)\n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    loader_good = Data(opt_good)\n",
    "    loader_bad = Data(opt_bad)\n",
    "    \n",
    "    test_loader_good = loader_good.loader_test\n",
    "    test_loader_bad = loader_bad.loader_test\n",
    "    if cascading:\n",
    "        filepath_good = f\"workspace/images/drn-l/{cas_model_name}/predicted_images/good\"\n",
    "        filepath_bad = f\"workspace/images/drn-l/{cas_model_name}/predicted_images/bad\"\n",
    "    else:\n",
    "        filepath_good = f\"workspace/images/drn-l/{model_name}/predicted_images/good\"\n",
    "        filepath_bad = f\"workspace/images/drn-l/{model_name}/predicted_images/bad\"\n",
    "    os.makedirs(filepath_good, exist_ok=True)\n",
    "    os.makedirs(filepath_bad, exist_ok=True)\n",
    "elif model_type == 'drct':\n",
    "    checkpoint = Checkpoint(opt_good)\n",
    "    model = Model(opt_good, checkpoint, dual_model=False)\n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    loader_good = Data(opt_good)\n",
    "    loader_bad = Data(opt_bad)\n",
    "    \n",
    "    test_loader_good = loader_good.loader_test\n",
    "    test_loader_bad = loader_bad.loader_test\n",
    "    if cascading:\n",
    "        filepath_good = f\"workspace/images/drct/{cas_model_name}/predicted_images/good\"\n",
    "        filepath_bad = f\"workspace/images/drct/{cas_model_name}/predicted_images/bad\"\n",
    "    else:\n",
    "        filepath_good = f\"workspace/images/drct/{model_name}/predicted_images/good\"\n",
    "        filepath_bad = f\"workspace/images/drct/{model_name}/predicted_images/bad\"\n",
    "    os.makedirs(filepath_good, exist_ok=True)\n",
    "    os.makedirs(filepath_bad, exist_ok=True)\n",
    "else:\n",
    "    print(\"Model_Type unknown!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f068c101-78f4-4d58-888a-7be6ee5ea429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 448/448 [00:21<00:00, 20.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    scale = opt_good.scale\n",
    "    for si, s in enumerate([scale]):\n",
    "        eval_psnr = 0\n",
    "        tqdm_test = tqdm(test_loader_good, ncols=80)\n",
    "        for _, (lr, hr, filename) in enumerate(tqdm_test):\n",
    "            filename = filename[0]\n",
    "            no_eval = (hr.nelement() == 1)\n",
    "            if not no_eval:\n",
    "                lr, hr = prepare(device, lr, hr)\n",
    "            else:\n",
    "                lr, = prepare(device, lr)\n",
    "\n",
    "            sr = model(lr[0])\n",
    "            \n",
    "            if isinstance(sr, list): sr = sr[-1]\n",
    "            \n",
    "            sr = quantize(sr, opt_good.rgb_range)\n",
    "                                            \n",
    "            # Save super-resolved image\n",
    "            filename = os.path.join(filepath_good, filename)\n",
    "            normalized = sr[0].data.mul(255 / opt_good.rgb_range)\n",
    "         \n",
    "            ndarr = normalized.byte().permute(1, 2, 0).cpu().numpy()\n",
    "           \n",
    "            # imageio.imwrite('{}.png'.format(filename), ndarr)\n",
    "            # Convert to PIL Image and save\n",
    "            if ndarr.ndim == 2:\n",
    "                img = Image.fromarray(ndarr, mode='L')\n",
    "            elif ndarr.ndim == 3:\n",
    "                if ndarr.shape[2] == 1:\n",
    "                    img = Image.fromarray(ndarr.squeeze(), mode='L')\n",
    "                elif ndarr.shape[2] == 3:\n",
    "                    img = Image.fromarray(ndarr, mode='RGB')\n",
    "                elif ndarr.shape[2] == 4:\n",
    "                    img = Image.fromarray(ndarr, mode='RGBA')\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected number of channels: {ndarr.shape[2]}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected number of dimensions: {ndarr.ndim}\")\n",
    "            \n",
    "            img.save(f'{filename}.png')\n",
    "\n",
    "print(\"Process completed.\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4263fead-2c95-4001-9c2b-53a5953c9f87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 448/448 [00:21<00:00, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    scale = opt_bad.scale\n",
    "    for si, s in enumerate([scale]):\n",
    "        eval_psnr = 0\n",
    "        tqdm_test = tqdm(test_loader_bad, ncols=80)\n",
    "        for _, (lr, hr, filename) in enumerate(tqdm_test):\n",
    "            filename = filename[0]\n",
    "            no_eval = (hr.nelement() == 1)\n",
    "            if not no_eval:\n",
    "                lr, hr = prepare(device, lr, hr)\n",
    "            else:\n",
    "                lr, = prepare(device, lr)\n",
    "\n",
    "            # Super-resolution model prediction\n",
    "            sr = model(lr[0])\n",
    "            if isinstance(sr, list): sr = sr[-1]\n",
    "            sr = quantize(sr, opt_bad.rgb_range)\n",
    "            \n",
    "            # Save super-resolved image\n",
    "            filename = os.path.join(filepath_bad, filename)\n",
    "            normalized = sr[0].data.mul(255 / opt_bad.rgb_range)\n",
    "            ndarr = normalized.byte().permute(1, 2, 0).cpu().numpy()\n",
    "            # imageio.imwrite('{}.png'.format(filename), ndarr)\n",
    "            if ndarr.ndim == 2:\n",
    "                img = Image.fromarray(ndarr, mode='L')\n",
    "            elif ndarr.ndim == 3:\n",
    "                if ndarr.shape[2] == 1:\n",
    "                    img = Image.fromarray(ndarr.squeeze(), mode='L')\n",
    "                elif ndarr.shape[2] == 3:\n",
    "                    img = Image.fromarray(ndarr, mode='RGB')\n",
    "                elif ndarr.shape[2] == 4:\n",
    "                    img = Image.fromarray(ndarr, mode='RGBA')\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected number of channels: {ndarr.shape[2]}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected number of dimensions: {ndarr.ndim}\")\n",
    "            \n",
    "            img.save(f'{filename}.png')\n",
    "\n",
    "\n",
    "print(\"Process completed.\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b6cfe9-d405-4ce1-9940-966b78e53671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dataset == 'mvtec':\n",
    "    if model_type == 'drn-l':\n",
    "        good_original_folder = f\"workspace/mvtec_anomaly_detection_modified/{mvtec_class}/test/HR_{resolution}/good/HR\"\n",
    "        bad_original_folder = f\"workspace/mvtec_anomaly_detection_modified/{mvtec_class}/test/HR_{resolution}/bad/HR\"\n",
    "        if cascading:\n",
    "            good_reconstructed_folder = f\"workspace/images/drn-l/{cas_model_name}/predicted_images/good\"\n",
    "            bad_reconstructed_folder = f\"workspace/images/drn-l/{cas_model_name}/predicted_images/bad\"\n",
    "            log_file_path = f\"workspace/images/drn-l/{cas_model_name}/scores.txt\"\n",
    "        else:\n",
    "            good_reconstructed_folder = f\"workspace/images/drn-l/{model_name}/predicted_images/good\"\n",
    "            bad_reconstructed_folder = f\"workspace/images/drn-l/{model_name}/predicted_images/bad\"\n",
    "            log_file_path = f\"workspace/images/drn-l/{model_name}/scores.txt\"\n",
    "    elif model_type == 'drct':\n",
    "        good_original_folder = f\"workspace/mvtec_anomaly_detection_modified/{mvtec_class}/test/HR_{resolution}/good/HR\"\n",
    "        bad_original_folder = f\"workspace/mvtec_anomaly_detection_modified/{mvtec_class}/test/HR_{resolution}/bad/HR\"\n",
    "        if cascading:\n",
    "            good_reconstructed_folder = f\"workspace/images/drct/{cas_model_name}/predicted_images/good\"\n",
    "            bad_reconstructed_folder = f\"workspace/images/drct/{cas_model_name}/predicted_images/bad\"\n",
    "            log_file_path = f\"workspace/images/drct/{cas_model_name}/scores.txt\"\n",
    "        else:\n",
    "            good_reconstructed_folder = f\"workspace/images/drct/{model_name}/predicted_images/good\"\n",
    "            bad_reconstructed_folder = f\"workspace/images/drct/{model_name}/predicted_images/bad\"\n",
    "            log_file_path = f\"workspace/images/drct/{model_name}/scores.txt\"\n",
    "    else:\n",
    "        print(\"Unknown Model Type\")\n",
    "elif dataset == 'gkd':\n",
    "    if model_type == 'drn-l':\n",
    "        good_original_folder = f\"workspace/gkd/{gkd_class}/test/HR_{resolution}/good/HR\"\n",
    "        bad_original_folder = f\"workspace/gkd/{gkd_class}/test/HR_{resolution}/bad/HR\"\n",
    "        if cascading:\n",
    "            good_reconstructed_folder = f\"workspace/images/drn-l/{cas_model_name}/predicted_images/good\"\n",
    "            bad_reconstructed_folder = f\"workspace/images/drn-l/{cas_model_name}/predicted_images/bad\"\n",
    "            log_file_path = f\"workspace/images/drn-l/{cas_model_name}/scores.txt\"\n",
    "        else:\n",
    "            good_reconstructed_folder = f\"workspace/images/drn-l/{model_name}/predicted_images/good\"\n",
    "            bad_reconstructed_folder = f\"workspace/images/drn-l/{model_name}/predicted_images/bad\"\n",
    "            log_file_path = f\"workspace/images/drn-l/{model_name}/scores.txt\"\n",
    "    elif model_type == 'drct':\n",
    "        good_original_folder = f\"workspace/gkd/{gkd_class}/test/HR_{resolution}/good/HR\"\n",
    "        bad_original_folder = f\"workspace/gkd/{gkd_class}/test/HR_{resolution}/bad/HR\"\n",
    "        if cascading:\n",
    "            good_reconstructed_folder = f\"workspace/images/drct/{cas_model_name}/predicted_images/good\"\n",
    "            bad_reconstructed_folder = f\"workspace/images/drct/{cas_model_name}/predicted_images/bad\"\n",
    "            log_file_path = f\"workspace/images/drct/{cas_model_name}/scores.txt\"\n",
    "        else:\n",
    "            good_reconstructed_folder = f\"workspace/images/drct/{model_name}/predicted_images/good\"\n",
    "            bad_reconstructed_folder = f\"workspace/images/drct/{model_name}/predicted_images/bad\"\n",
    "            log_file_path = f\"workspace/images/drct/{model_name}/scores.txt\"\n",
    "    else:\n",
    "        print(\"Unknown Model Type\")\n",
    "else: \n",
    "    print(\"Unknown Dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6048fa-7528-473e-9dd6-e1dd0d9d062d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best window size (max difference): 103\n",
      "Max difference in SSIM scores: -0.0254\n",
      "Best window size (max AUC): 123\n",
      "Max AUC: 0.8955\n",
      "Number of samples: 64\n",
      "Number of anomalies: 32\n",
      "Number of normal samples: 32\n",
      "AUC-ROC (SSIM): 0.8955\n",
      "AUC-ROC (MSE): 0.7471\n",
      "AUC-ROC (PSNR): 0.8828\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'mvtec':\n",
    "    analysis_results = analyze_window_sizes(good_original_folder, good_reconstructed_folder,\n",
    "                                            bad_original_folder, bad_reconstructed_folder)\n",
    "\n",
    "    print(f\"Best window size (max difference): {analysis_results['best_window_size']}\")\n",
    "    print(f\"Max difference in SSIM scores: {analysis_results['max_difference']:.4f}\")\n",
    "    print(f\"Best window size (max AUC): {analysis_results['best_auc_window_size']}\")\n",
    "    print(f\"Max AUC: {analysis_results['max_auc']:.4f}\")\n",
    "    # Choose which window size to use (max difference or max AUC)\n",
    "    chosen_window_size = analysis_results['best_auc_window_size']\n",
    "\n",
    "    y_true, y_scores_ssim, y_scores_mse, y_scores_psnr = process_images(\n",
    "        good_original_folder, good_reconstructed_folder,\n",
    "        bad_original_folder, bad_reconstructed_folder,\n",
    "        log_file_path, chosen_window_size\n",
    "    )\n",
    "\n",
    "    r_a_ssim = roc_auc_score(y_true, y_scores_ssim)\n",
    "    r_a_mse = roc_auc_score(y_true, y_scores_mse)\n",
    "    r_a_psnr = roc_auc_score(y_true, y_scores_psnr)\n",
    "    print(f\"Number of samples: {len(y_true)}\")\n",
    "    print(f\"Number of anomalies: {sum(y_true)}\")\n",
    "    print(f\"Number of normal samples: {len(y_true) - sum(y_true)}\")\n",
    "    print(f\"AUC-ROC (SSIM): {r_a_ssim:.4f}\")\n",
    "    print(f\"AUC-ROC (MSE): {r_a_mse:.4f}\")\n",
    "    print(f\"AUC-ROC (PSNR): {r_a_psnr:.4f}\")\n",
    "elif dataset == 'gkd':\n",
    "    analysis_results = analyze_window_sizes_gkd(good_original_folder, good_reconstructed_folder,\n",
    "                                            bad_original_folder, bad_reconstructed_folder)\n",
    "\n",
    "    print(f\"Best window size (max difference): {analysis_results['best_window_size']}\")\n",
    "    print(f\"Max difference in SSIM scores: {analysis_results['max_difference']:.4f}\")\n",
    "    print(f\"Best window size (max AUC): {analysis_results['best_auc_window_size']}\")\n",
    "    print(f\"Max AUC: {analysis_results['max_auc']:.4f}\")\n",
    "    # Choose which window size to use (max difference or max AUC)\n",
    "    chosen_window_size = analysis_results['best_auc_window_size']\n",
    "\n",
    "    y_true, y_scores_ssim, y_scores_mse, y_scores_psnr = process_gkd_images(\n",
    "        good_original_folder, good_reconstructed_folder,\n",
    "        bad_original_folder, bad_reconstructed_folder,\n",
    "        log_file_path, chosen_window_size\n",
    "    )\n",
    "    r_a_ssim = roc_auc_score(y_true, y_scores_ssim)\n",
    "    r_a_mse = roc_auc_score(y_true, y_scores_mse)\n",
    "    r_a_psnr = roc_auc_score(y_true, y_scores_psnr)\n",
    "    print(f\"Number of samples: {len(y_true)}\")\n",
    "    print(f\"Number of anomalies: {sum(y_true)}\")\n",
    "    print(f\"Number of normal samples: {len(y_true) - sum(y_true)}\")\n",
    "    print(f\"AUC-ROC (SSIM): {r_a_ssim:.4f}\")\n",
    "    print(f\"AUC-ROC (MSE): {r_a_mse:.4f}\")\n",
    "    print(f\"AUC-ROC (PSNR): {r_a_psnr:.4f}\")\n",
    "else: \n",
    "    print(\"Unknown Dataset!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54298384-dba1-441c-a410-56fd4d628cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51fb20d-c732-4b4b-a0bf-e93a741f5938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score ssim: 0.90\n",
      "Accuracy: 0.84\n",
      "Precision: 0.87\n",
      "Recall: 0.81\n",
      "F1-score: 0.84\n",
      "gkd_DC2_128_X813:59:20\n"
     ]
    }
   ],
   "source": [
    "# Plot ROC curve and get AUC score\n",
    "auc_score = plot_roc_curve(y_true, y_scores_ssim)\n",
    "print(f\"AUC score ssim: {auc_score:.2f}\")\n",
    "\n",
    "# Find optimal threshold\n",
    "optimal_threshold = find_optimal_threshold(y_true, y_scores_ssim)\n",
    "# print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n",
    "\n",
    "# Classify images based on the optimal threshold\n",
    "predictions = (y_scores_ssim >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predictions == y_true)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, predictions)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, predictions)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_true, predictions)\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52da907f-efaf-4a57-9efb-e8df848cb367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score mse: 0.75\n",
      "Accuracy: 0.80\n",
      "Precision: 0.95\n",
      "Recall: 0.62\n",
      "F1-score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Plot ROC curve and get AUC score\n",
    "auc_score = plot_roc_curve(y_true, y_scores_mse)\n",
    "print(f\"AUC score mse: {auc_score:.2f}\")\n",
    "\n",
    "# Find optimal threshold\n",
    "optimal_threshold = find_optimal_threshold(y_true, y_scores_mse)\n",
    "# print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n",
    "\n",
    "# Classify images based on the optimal threshold\n",
    "predictions = (y_scores_mse >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predictions == y_true)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, predictions)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, predictions)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_true, predictions)\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d63a712-d0b5-4c26-8464-2fef4c456365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score psnr: 0.88\n",
      "Accuracy: 0.86\n",
      "Precision: 0.87\n",
      "Recall: 0.84\n",
      "F1-score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Plot ROC curve and get AUC score\n",
    "auc_score = plot_roc_curve(y_true, y_scores_psnr)\n",
    "print(f\"AUC score psnr: {auc_score:.2f}\")\n",
    "\n",
    "# Find optimal threshold\n",
    "optimal_threshold = find_optimal_threshold(y_true, y_scores_psnr)\n",
    "# print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n",
    "\n",
    "# Classify images based on the optimal threshold\n",
    "predictions = (y_scores_psnr >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predictions == y_true)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, predictions)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, predictions)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_true, predictions)\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7572d-7c69-4d35-ae5a-cb4b6b2e1d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniconda",
   "language": "python",
   "name": "miniconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
